from PIL import Image, ImageDraw, ImageFont
import numpy as np
import os
import platform
import subprocess
import logging
import unicodedata
from functools import lru_cache
from typing import List, Tuple, Optional

# å¯é€‰ä¾èµ–ï¼ˆä½¿ç”¨æœ¬åœ° try/except ç¡®ä¿æ¨¡å—çº§å¯¼å…¥å¤±è´¥ä¸å½±å“ä»£ç è¿è¡Œï¼‰
try:
    import langdetect

    HAS_LANGDETECT = True
except ImportError:
    HAS_LANGDETECT = False

try:
    from fontTools.ttLib import TTFont

    HAS_FONTTOOLS = True
except ImportError:
    HAS_FONTTOOLS = False

# --- âš™ï¸ å…¨å±€é…ç½®å’Œå¸¸é‡ ---
# æ”¯æŒè¯­è¨€ç™½åå•
SUPPORTED_LANGS = {'en', 'zh-Hans', 'zh-Hant', 'ja', 'ko', 'th', 'vi', 'de', 'es', 'pt'}

# æ— ç©ºæ ¼é€å­—æ¢è¡Œè¯­è¨€
NO_SPACE_WRAP_LANGS = {'zh-Hans', 'zh-Hant', 'ja', 'ko', 'th'}

# Unicode åŒºå—ç”¨äºç²—ç•¥è„šæœ¬æ£€æµ‹
UNICODE_BLOCKS = {
    'CJK': (0x4E00, 0x9FFF),
    'HANGUL': (0xAC00, 0xD7AF),
    'THAI': (0x0E00, 0x0E7F),
}

# Noto Sans CJK .ttc å­—ä½“ç´¢å¼•æ˜ å°„ï¼ˆå›ºå®šå€¼ï¼‰
TTC_INDEX_MAP = {
    'zh-Hans': 0,  # ç®€ä½“ä¸­æ–‡
    'zh-Hant': 1,  # ç¹ä½“ä¸­æ–‡
    'ja': 2,  # æ—¥æ–‡
    'ko': 3,  # éŸ©æ–‡
}

# å¸¸è§ Noto CJK/é€šç”¨å­—ä½“è·¯å¾„ (Linux ä¼˜å…ˆ)
COMMON_FONT_PATHS = [
    "/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc",
    "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",
    "/usr/share/fonts/truetype/noto-cjk/NotoSansCJK-Regular.ttc",
    "/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc",
    "/usr/share/fonts/truetype/noto/NotoSansThai-Regular.ttf",
    "/usr/share/fonts/opentype/noto/NotoSansThai-Regular.otf",
    "/usr/share/fonts/truetype/noto/NotoSans-Regular.ttf",
    "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf",
    "/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf",
]


# --- æ ¸å¿ƒå‡½æ•° ---

def find_split_line(pixel_array: np.ndarray, axis: int, expected_pos: float, search_margin: int) -> int:
    """
    åœ¨å›¾åƒçš„ç°åº¦åƒç´ æ•°ç»„ä¸­å¯»æ‰¾æœ€æš—ï¼ˆå¹³å‡å€¼æœ€ä½ï¼‰çš„åˆ†å‰²çº¿ã€‚
    axis=0 æ‰¾æ°´å¹³çº¿ (row)ï¼Œaxis=1 æ‰¾å‚ç›´çº¿ (col)ã€‚
    """
    if axis == 1:
        # å¯»æ‰¾å‚ç›´åˆ†å‰²çº¿ (col)
        search_start = max(0, int(expected_pos - search_margin))
        search_end = min(pixel_array.shape[1], int(expected_pos + search_margin))
        roi = pixel_array[:, search_start:search_end]
        if roi.size == 0: return int(expected_pos)
        # æ±‚æ¯åˆ—çš„å¹³å‡å€¼
        line_averages = np.mean(roi, axis=0)
        min_index = int(np.argmin(line_averages))
        return search_start + min_index
    else:
        # å¯»æ‰¾æ°´å¹³åˆ†å‰²çº¿ (row)
        search_start = max(0, int(expected_pos - search_margin))
        search_end = min(pixel_array.shape[0], int(expected_pos + search_margin))
        roi = pixel_array[search_start:search_end, :]
        if roi.size == 0: return int(expected_pos)
        # æ±‚æ¯è¡Œçš„å¹³å‡å€¼
        line_averages = np.mean(roi, axis=1)
        min_index = int(np.argmin(line_averages))
        return search_start + min_index


def detect_text_script(text: str) -> str:
    """ç²—ç•¥åœ°æ ¹æ® Unicode åŒºå—æ£€æµ‹æ–‡æœ¬çš„ä¸»è„šæœ¬ã€‚"""
    script_counts = {'CJK': 0, 'HANGUL': 0, 'THAI': 0, 'Latin': 0}
    for char in text:
        code_point = ord(char)
        matched = False
        for script, (start, end) in UNICODE_BLOCKS.items():
            if start <= code_point <= end:
                script_counts[script] += 1
                matched = True
                break
        if not matched and not char.isspace() and 'L' in unicodedata.category(char):
            script_counts['Latin'] += 1

    main_script = max(script_counts, key=script_counts.get)
    return main_script if script_counts[main_script] > 0 else 'Latin'


@lru_cache(maxsize=1)
def get_system_fonts() -> List[Tuple[str, str]]:
    """è·å–ç³»ç»Ÿå­—ä½“åˆ—è¡¨ (Family Name, File Path)ã€‚ä¼˜å…ˆä½¿ç”¨ fc-listã€‚"""
    # ä¼˜å…ˆä½¿ç”¨ fc-list (Linux)
    try:
        result = subprocess.run(['fc-list', ':', 'family,file'],
                                capture_output=True, text=True, timeout=3, check=False)
        if result.returncode == 0 and result.stdout:
            fonts = []
            for line in result.stdout.strip().split('\n'):
                if ':' in line:
                    parts = line.split(':', 1)
                    # ä»…å–ç¬¬ä¸€ä¸ª Family Name å’Œç¬¬ä¸€ä¸ª File Path
                    family = parts[0].strip().split(',')[0].strip()
                    file_path = parts[1].strip().split(',')[0].strip()
                    if family and file_path:
                        fonts.append((family, file_path))
            logging.debug(f"é€šè¿‡ fc-list æ‰¾åˆ° {len(fonts)} ä¸ªå­—ä½“ã€‚")
            return fonts
    except Exception as e:
        logging.debug(f"fc-list å¤±è´¥æˆ–ä¸å¯ç”¨: {e}")

    # Windows å›é€€
    if platform.system() == "Windows":
        windows_font_path = os.environ.get('WINDIR', 'C:\\Windows') + '\\Fonts'
        if os.path.isdir(windows_font_path):
            win_fonts = [(f.split('.')[0], os.path.join(windows_font_path, f))
                         for f in os.listdir(windows_font_path)
                         if f.lower().endswith(('.ttf', '.ttc', '.otf'))]
            logging.debug(f"é€šè¿‡ Windows ç›®å½•æ‰¾åˆ° {len(win_fonts)} ä¸ªå­—ä½“ã€‚")
            return win_fonts

    logging.warning("æœªæ‰¾åˆ°å¯ç”¨çš„ç³»ç»Ÿå­—ä½“åˆ—è¡¨å·¥å…· (fc-list æˆ– Windows è·¯å¾„)ã€‚")
    return []


# é€‚é… .ttc å­—ä½“çš„å­—ç¬¦æ£€æŸ¥ï¼ˆæŒ‡å®šç´¢å¼•ï¼‰
def check_font_has_text(font_path: Optional[str], text: str, font_index: int = 0) -> bool:
    """æ£€æŸ¥å­—ä½“æ˜¯å¦åŒ…å«æ–‡æœ¬ä¸­çš„æ‰€æœ‰éç©ºç™½å­—ç¬¦ã€‚"""
    if not HAS_FONTTOOLS or not font_path or not os.path.exists(font_path):
        return True  # æ— æ³•æ£€æŸ¥æ—¶ï¼Œå‡è®¾æ”¯æŒ
    try:
        tt = TTFont(font_path, fontNumber=font_index)
        cmap = tt.getBestCmap()
        tt.close()
        for c in text:
            if c.isspace():
                continue
            if ord(c) not in cmap:
                return False
        return True
    except Exception as e:
        logging.debug(f"æ£€æŸ¥å­—ä½“ {font_path}ï¼ˆç´¢å¼• {font_index}ï¼‰å¤±è´¥: {e}")
        return True  # æ£€æŸ¥å¤±è´¥æ—¶ï¼Œå‡è®¾æ”¯æŒä»¥é¿å…è¯¯åˆ¤


# é€‚é… .ttc å­—ä½“çš„è¯Šæ–­ï¼ˆæŒ‡å®šç´¢å¼•ï¼‰
def diagnose_font_issues(text: str, font_path: Optional[str], font_index: int = 0):
    """è¯Šæ–­æ–‡æœ¬ä¸­ç¼ºå¤±çš„å­—ç¬¦å¹¶ç»™å‡ºå®‰è£…å»ºè®®ã€‚"""
    if not HAS_FONTTOOLS or not font_path or not os.path.exists(font_path):
        return
    try:
        tt = TTFont(font_path, fontNumber=font_index)
        cmap = tt.getBestCmap()
        tt.close()
        missing = [c for c in text if (not c.isspace()) and (ord(c) not in cmap)]
        if missing:
            logging.warning(
                f"æ£€æµ‹åˆ°{len(missing)}ä¸ªæ— æ³•æ¸²æŸ“çš„å­—ç¬¦ï¼ˆå­—ä½“ï¼š{os.path.basename(font_path)}ï¼Œç´¢å¼•ï¼š{font_index}ï¼‰ã€‚")
            # ç»™å‡ºå®‰è£…å»ºè®®
            if any(0x4E00 <= ord(c) <= 0x9FFF for c in missing):
                logging.warning("ï¼ˆä¸­æ–‡/æ—¥æ–‡/éŸ©æ–‡ï¼‰å»ºè®®å®‰è£… Noto CJK: sudo apt install fonts-noto-cjk -y")
            if any(0x0E00 <= ord(c) <= 0x0E7F for c in missing):
                logging.warning("ï¼ˆæ³°æ–‡ï¼‰å»ºè®®å®‰è£… Noto Thai: sudo apt install fonts-noto-thai -y")
    except Exception:
        pass


@lru_cache(maxsize=128)
def normalize_lang(text: str) -> str:
    """è§„èŒƒåŒ–è¯­è¨€ä»£ç ï¼Œé¦–å…ˆå°è¯• langdetectï¼Œå›é€€åˆ°è„šæœ¬æ£€æµ‹ã€‚"""
    lang = None
    if HAS_LANGDETECT and text.strip():
        try:
            lang = langdetect.detect(text)
        except Exception:
            lang = None

    mapping = {
        'en': 'en', 'de': 'de', 'es': 'es', 'pt': 'pt',
        'ja': 'ja', 'ko': 'ko', 'th': 'th', 'vi': 'vi',
        'zh': 'zh-Hans', 'zh-cn': 'zh-Hans', 'zh-sg': 'zh-Hans',
        'zh-tw': 'zh-Hant', 'zh-hk': 'zh-Hant', 'zh-mo': 'zh-Hant',
    }
    if lang in mapping:
        norm = mapping[lang]
        if norm in SUPPORTED_LANGS:
            return norm

    # å›é€€åŸºäºè„šæœ¬
    script = detect_text_script(text)
    if script == 'CJK':
        return 'zh-Hans'
    if script == 'HANGUL':
        return 'ko'
    if script == 'THAI':
        return 'th'
    # é»˜è®¤è‹±æ–‡
    return 'en'


def list_existing_paths(paths: List[str]) -> List[str]:
    """è¿‡æ»¤åªä¿ç•™å®é™…å­˜åœ¨çš„æ–‡ä»¶è·¯å¾„ã€‚"""
    existing = [p for p in paths if os.path.exists(p)]
    return existing


def try_load_font(path: str, size: int, index: int = 0) -> Optional[ImageFont.FreeTypeFont]:
    """å°è¯•åŠ è½½å­—ä½“æ–‡ä»¶ï¼Œå¤±è´¥åˆ™è¿”å› Noneã€‚"""
    try:
        # åŠ è½½ .ttc æ—¶æŒ‡å®šç´¢å¼•
        font = ImageFont.truetype(path, size, index=index)
        logging.debug(f"æˆåŠŸåŠ è½½å­—ä½“ï¼š{path}ï¼ˆç´¢å¼• {index}ï¼Œå¤§å° {size}ï¼‰")
        return font
    except Exception as e:
        logging.debug(f"åŠ è½½å­—ä½“å¤±è´¥ï¼š{path}ï¼ˆç´¢å¼• {index}ï¼‰ï¼š{e}")
        return None


def search_system_font_by_keywords(keywords: List[str], size: int) -> Tuple[
    Optional[ImageFont.FreeTypeFont], Optional[str]]:
    """é€šè¿‡å…³é”®è¯åœ¨ç³»ç»Ÿå­—ä½“ä¸­æœç´¢å¹¶åŠ è½½å­—ä½“ã€‚"""
    fonts = get_system_fonts()
    for family, file_path in fonts:
        hay = (family + " " + os.path.basename(file_path)).lower()
        if any(k in hay for k in keywords):
            # CJK å­—ä½“åœ¨ fc-list ä¸­å¯èƒ½æ²¡æœ‰åŒ…å«ç´¢å¼•ä¿¡æ¯ï¼Œç›´æ¥å°è¯•åŠ è½½ 0 ç´¢å¼•
            f = try_load_font(file_path, size, index=0)
            if f:
                return f, file_path
    return None, None


def get_font_for_language(font_size: int, lang: str, sample_text: str = "") -> Tuple[
    ImageFont.FreeTypeFont, Optional[str]]:
    """æ ¹æ®è¯­è¨€é€‰æ‹©åˆé€‚çš„å­—ä½“å’Œè·¯å¾„ã€‚"""
    candidates = []
    font_index = TTC_INDEX_MAP.get(lang, 0)

    # æ ¹æ®è¯­è¨€ç±»å‹è¿‡æ»¤å¸¸ç”¨è·¯å¾„åˆ—è¡¨
    if lang in {'zh-Hans', 'zh-Hant', 'ja', 'ko'}:
        candidates = [p for p in COMMON_FONT_PATHS if 'CJK' in p] + candidates
    elif lang == 'th':
        candidates = [p for p in COMMON_FONT_PATHS if 'Thai' in p] + candidates
    else:  # æ‹‰ä¸/è¶Šå—è¯­/è¥¿æ–‡é€šç”¨
        candidates = [p for p in COMMON_FONT_PATHS if 'CJK' not in p and 'Thai' not in p] + candidates

    # å°è¯•è·¯å¾„åŠ è½½
    for path in list_existing_paths(candidates):
        # å¦‚æœæ˜¯ ttc ä¸”æ˜¯ CJK è¯­è¨€ï¼Œä½¿ç”¨å¯¹åº”çš„ç´¢å¼•
        current_index = font_index if path.lower().endswith('.ttc') and lang in TTC_INDEX_MAP else 0
        f = try_load_font(path, font_size, index=current_index)
        if f:
            if not sample_text or check_font_has_text(path, sample_text, font_index=current_index):
                logging.info(f"æˆåŠŸé€‰æ‹©å­—ä½“ï¼š{os.path.basename(path)}ï¼ˆè¯­è¨€ï¼š{lang}ï¼Œç´¢å¼•ï¼š{current_index}ï¼‰")
                return f, path

    # ç³»ç»Ÿå…³é”®è¯æœç´¢
    keywords_map = {
        'zh-Hans': ['noto sans cjk', 'sc', 'simplified', 'noto cjk'],
        'zh-Hant': ['noto sans cjk', 'tc', 'traditional', 'noto cjk'],
        'ja': ['noto sans cjk', 'jp', 'source han sans'],
        'ko': ['noto sans cjk', 'kr', 'source han sans'],
        'th': ['noto sans thai', 'thai'],
        'vi': ['noto sans', 'dejavu sans', 'viet', 'liberation sans'],
        'en': ['noto sans', 'dejavu sans', 'arial', 'liberation sans'],
    }
    f, p = search_system_font_by_keywords(keywords_map.get(lang, ['noto sans']), font_size)
    if f:
        logging.info(f"é€šè¿‡å…³é”®è¯æœç´¢é€‰æ‹©å­—ä½“ï¼š{os.path.basename(p)}ï¼ˆè¯­è¨€ï¼š{lang}ï¼‰")
        return f, p

    # æœ€ç»ˆå…œåº•
    logging.error(f"æœªæ‰¾åˆ° {lang} åˆé€‚å­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“ã€‚")
    return ImageFont.load_default(), None


def wrap_text(text: str, max_width: int, draw: ImageDraw.ImageDraw, font: ImageFont.FreeTypeFont,
              language: Optional[str] = None) -> List[str]:
    """æ ¹æ®æœ€å¤§å®½åº¦å’Œè¯­è¨€ç±»å‹è¿›è¡Œæ–‡æœ¬æ¢è¡Œã€‚"""
    lines: List[str] = []
    current_line = ""

    # é€å­—æ¢è¡Œï¼ˆä¸­æ–‡/æ—¥æ–‡/éŸ©æ–‡/æ³°æ–‡ï¼‰
    if language in NO_SPACE_WRAP_LANGS:
        for char in text:
            char_width = draw.textlength(char, font=font)

            # ä½¿ç”¨ try/except æ•è·å½“å‰è¡Œå®½åº¦
            try:
                current_width = draw.textlength(current_line, font=font)
            except Exception:
                # å…¼å®¹æ—§ç‰ˆ Pillow æˆ–å¼‚å¸¸æƒ…å†µï¼Œä½¿ç”¨ approximate size
                current_width = font.getsize(current_line)[0]

            if current_width + char_width <= max_width or not current_line:
                current_line += char
            else:
                if current_line.strip():
                    lines.append(current_line)
                current_line = char
        if current_line.strip():
            lines.append(current_line.rstrip())
        return lines

    # æŒ‰ç©ºæ ¼æ¢è¡Œï¼ˆè¥¿æ–‡/è¶Šå—è¯­ï¼‰
    tokens = text.split()
    current_width = 0
    for token in tokens:
        token_with_space = token + " "
        token_width = draw.textlength(token_with_space, font=font)

        # æ¢è¡Œæ¡ä»¶
        if current_width + token_width <= max_width or not current_line:
            current_line += token_with_space
            current_width += token_width
        else:
            if current_line.strip():
                lines.append(current_line.rstrip())
            current_line = token_with_space
            current_width = token_width

    if current_line.strip():
        lines.append(current_line.rstrip())
    return lines


def add_multilingual_captions_to_nx1_image(
        image_path: str, captions: List[str], output_path: str, margin: int = 30,
        font_size: int = 24, font_color: Tuple[int, ...] = (255, 255, 255, 255),
        padding: int = 10, max_width_ratio: float = 0.9
) -> bool:
    """
    ä¸º N x 1 å¸ƒå±€çš„å›¾ç‰‡ï¼ˆN ä¸ªå‚ç›´ç‰‡æ®µï¼‰æ·»åŠ å±…ä¸­æ–‡æœ¬å­—å¹•ã€‚
    è‡ªåŠ¨æ£€æµ‹è¯­è¨€ã€é€‰æ‹©å­—ä½“å¹¶å¤„ç† CJK/é CJK æ¢è¡Œã€‚
    """
    n = len(captions)
    if n < 1:
        logging.error("é”™è¯¯ï¼šè‡³å°‘éœ€è¦ä¸€æ¡å­—å¹•ã€‚")
        return False

    try:
        img = Image.open(image_path)
    except Exception as e:
        logging.error(f"æ‰“å¼€å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        return False

    width, height = img.size

    # --- 1. è‡ªåŠ¨åˆ†å‰²çº¿ï¼ˆæ°´å¹³ï¼‰ ---
    img_gray = img.convert('L')
    pixels = np.array(img_gray)
    h_lines = []

    # âœ¨ å¢å¼ºæ—¥å¿— - æ˜¾ç¤ºåˆ†å‰²æ£€æµ‹åˆå§‹åŒ–ä¿¡æ¯
    logging.info(f"ğŸ” åˆ†å‰²çº¿æ£€æµ‹åˆå§‹åŒ– | å›¾ç‰‡å°ºå¯¸: {width}x{height} | ç›®æ ‡åˆ†å‰²æ•°: {n}æ®µ | è¾¹è·é˜ˆå€¼: {margin}px")

    for i in range(1, n):
        expected_h = height * i / n
        # å¯»æ‰¾æœ€æš—çš„åˆ†å‰²çº¿
        h_line = find_split_line(pixels, axis=0, expected_pos=expected_h, search_margin=margin)
        h_lines.append(h_line)

        # âœ¨ å¢å¼ºæ—¥å¿— - æ˜¾ç¤ºæ¯æ¡åˆ†å‰²çº¿çš„è¯¦ç»†ä¿¡æ¯
        deviation = abs(h_line - expected_h)
        status = "âœ… æˆåŠŸ" if deviation <= margin else "âš ï¸ åå·®è¾ƒå¤§"
        logging.info(
            f"{status} åˆ†å‰²çº¿ #{i} | "
            f"é¢„æœŸä½ç½®: {expected_h:.1f}px | "
            f"æ£€æµ‹ä½ç½®: {h_line}px | "
            f"åå·®: {deviation:.1f}px | "
            f"æœç´¢èŒƒå›´: [{max(0, expected_h - margin):.1f}, {min(height, expected_h + margin):.1f}]"
        )

    # âœ¨ å¢å¼ºæ—¥å¿— - æ˜¾ç¤ºå®Œæ•´åˆ†å‰²ç‚¹åºåˆ—å’Œå„æ®µé«˜åº¦
    y_points = [0] + h_lines + [height]
    segments = [y_points[i + 1] - y_points[i] for i in range(len(y_points) - 1)]
    logging.info(f"ğŸ“Š æœ€ç»ˆåˆ†å‰²ç‚¹åºåˆ—: {y_points}")
    logging.info(f"ğŸ“ å„æ®µé«˜åº¦åˆ†å¸ƒ: {segments} | å¹³å‡é«˜åº¦: {height / n:.1f}px")

    img_with_captions = img.copy()
    # é¢œè‰²å¸¦ alpha æ—¶ç¡®ä¿ RGBA
    if img_with_captions.mode != 'RGBA' and len(font_color) == 4:
        img_with_captions = img_with_captions.convert('RGBA')
    draw = ImageDraw.Draw(img_with_captions)

    # --- 2. é€æ®µæ·»åŠ å­—å¹• ---
    for i in range(n):
        top = y_points[i]
        bottom = y_points[i + 1]
        caption = captions[i]

        language = normalize_lang(caption)
        if language not in SUPPORTED_LANGS:
            logging.warning(f"æ£€æµ‹åˆ°ä¸åœ¨ç™½åå•å†…çš„è¯­è¨€ï¼ŒæŒ‰ 'en' å¤„ç†ã€‚ç‰‡æ®µ: {caption[:16]}...")
            language = 'en'

        # ä¸ºæœ¬æ¡å­—å¹•é€‰æ‹©å­—ä½“
        font, font_path = get_font_for_language(font_size, language, sample_text=caption)

        # å­—ä½“è¯Šæ–­
        font_index = TTC_INDEX_MAP.get(language, 0)
        diagnose_font_issues(caption, font_path, font_index=font_index)

        # æ–‡æœ¬æ¢è¡Œ
        max_caption_width = int(width * max_width_ratio)
        lines = wrap_text(caption, max_caption_width, draw, font, language=language)

        # è®¡ç®—æ–‡æœ¬æ€»é«˜åº¦
        total_text_height = 0
        line_heights = []
        for line in lines:
            try:
                # ä½¿ç”¨ textbbox å‡†ç¡®è®¡ç®—è¡Œé«˜
                bbox = draw.textbbox((0, 0), line, font=font)
                lh = bbox[3] - bbox[1]
            except Exception:
                # å…œåº•è®¡ç®—
                lh = font_size + 4
            line_heights.append(lh)
            total_text_height += lh

        if len(lines) > 1:
            total_text_height += padding * (len(lines) - 1)

        # åº•éƒ¨å†…è¾¹è·æ˜¾ç¤ºï¼šæ–‡æœ¬çš„é¡¶éƒ¨ Y åæ ‡
        text_y_start = bottom - total_text_height - padding
        current_y = text_y_start

        # ç»˜åˆ¶æ–‡æœ¬è¡Œ
        for j, line in enumerate(lines):
            line_height = line_heights[j]
            try:
                # é‡æ–°è®¡ç®—å®½åº¦ä»¥å±…ä¸­
                bbox = draw.textbbox((0, 0), line, font=font)
                line_width = bbox[2] - bbox[0]
            except Exception:
                line_width = draw.textlength(line, font=font)  # è‡³å°‘å°è¯•ç”¨ textlength
                if line_width == 0:
                    line_width = int(len(line) * font_size * 0.6)  # æœ€ç»ˆå…œåº•

            text_x = (width - line_width) // 2  # å±…ä¸­

            try:
                draw.text((text_x, current_y), line, font=font, fill=font_color)
            except Exception as e:
                logging.error(f"ç»˜åˆ¶æ–‡æœ¬æ—¶å‡ºé”™: {e}")

            # æ›´æ–°ä¸‹ä¸€è¡Œçš„ Y åæ ‡
            current_y += line_height + (padding if j < len(lines) - 1 else 0)

    # --- 3. ä¿å­˜ç»“æœ ---
    result = img_with_captions
    # JPG ä¸æ”¯æŒ Alpha é€šé“ï¼Œéœ€è¦è½¬ RGB
    if output_path.lower().endswith(('.jpg', '.jpeg')) and result.mode == 'RGBA':
        # ä½¿ç”¨ç™½è‰²èƒŒæ™¯èåˆ Alpha
        background = Image.new('RGB', result.size, (255, 255, 255))
        background.paste(result, mask=result.split()[3])  # ç²˜è´´æ—¶ä½¿ç”¨ Alpha é€šé“ä½œä¸ºè’™ç‰ˆ
        result = background

    try:
        result.save(output_path)
        logging.info(f"å­—å¹•æ·»åŠ å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")
        return True
    except Exception as e:
        logging.error(f"ä¿å­˜å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        return False




if __name__ == "__main__":
    # é…ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.StreamHandler(),
            logging.FileHandler('../test/split_images.log', mode='w', encoding='utf-8')
        ]
    )

    multilingual_captions = [
        "ç®€ä½“ä¸­æ–‡",
        # "ç¹é«”ä¸­æ–‡ï¼Œéœ€è¦å–®å­—ç¬¦æ›è¡Œã€‚",
        "ã“ã‚Œã¯æ—¥æœ¬èªã®ä¾‹ã§ã™ã€‚",
        "ì´ê²ƒì€ í•œêµ­ì–´ ì˜ˆì‹œì…ë‹ˆë‹¤.",
        # "à¸™à¸µà¹ˆà¸„à¸·à¸­à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ à¸—à¸µà¹ˆà¸­à¸²à¸ˆà¸¢à¸²à¸§à¹€à¸à¸´à¸™à¹„à¸›",
        # "ÄÃ¢y lÃ  vÃ­ dá»¥ tiáº¿ng Viá»‡t cÃ³ dáº¥u vÃ  cáº§n há»— trá»£ tá»‘t tá»« font chá»¯.",
        # "English, which will be wrapped by spaces automatically.",
        # "Deutsch ist eine schÃ¶ne Sprache, die Leerzeichen fÃ¼r die Worttrennung verwendet.",
        # "El espaÃ±ol es un idioma muy bonito que usa espacios.",
        # "O portuguÃªs Ã© uma lÃ­ngua que usa espaÃ§os para a quebra de linha.",
    ]

    # è¯·æ›¿æ¢ä¸ºä½ çš„å®é™…å›¾ç‰‡è·¯å¾„
    # æ³¨æ„ï¼šæ­¤å¤„ä½¿ç”¨çš„è·¯å¾„ä¸ºåŸä»£ç ä¸­çš„ç¡¬ç¼–ç è·¯å¾„ï¼Œéœ€è¦ç¡®ä¿å®ƒä»¬åœ¨æ‚¨çš„è¿è¡Œç¯å¢ƒä¸­æ˜¯æ­£ç¡®çš„ã€‚
    input_image = "/home/cz/software/pycharm-2024.2.3/PycharmProjects/python-utils/assets/grid/three/1762324473013-SJQJmMMK-0.jpg"
    output_dir = "/assets/grid/output"

    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    output_image = os.path.join(output_dir, "0009.png")

    logging.info("\n" + "=" * 50)
    logging.info("å¼€å§‹æ·»åŠ ç²¾é€‰è¯­ç§å­—å¹•...")
    logging.info("=" * 50)

    # æ¸…é™¤ç¼“å­˜ï¼Œç¡®ä¿æ¯æ¬¡è¿è¡Œéƒ½é‡æ–°åŠ è½½ç³»ç»Ÿå­—ä½“
    get_system_fonts.cache_clear()
    normalize_lang.cache_clear()

    success = add_multilingual_captions_to_nx1_image(
        image_path=input_image,
        captions=multilingual_captions,
        output_path=output_image,
        margin=8,
        font_size=20,
        font_color=(255, 255, 255, 255),
        padding=25,
        max_width_ratio=0.9
    )

    if not success:
        logging.error("\n" + "=" * 50)
        logging.error("å­—å¹•æ·»åŠ å¤±è´¥ï¼è¯·æ£€æŸ¥å­—ä½“å®‰è£…ã€‚")
        logging.error("æ¨èå®‰è£…ï¼ˆLinuxï¼‰ï¼šsudo apt install fonts-noto-cjk fonts-noto-cjk-extra fonts-noto -y")
        logging.error("=" * 50)
    else:
        logging.info("\n" + "=" * 50)
        logging.info(f"å­—å¹•æ·»åŠ æˆåŠŸï¼è¯·æ£€æŸ¥ {output_image}")
        logging.info("å¦‚æ³°è¯­/è¶Šå—è¯­æœ‰ç¼ºå­—ï¼Œè¯·ç¡®è®¤ Noto Sans/Thai å·²å®‰è£…ã€‚")
        logging.info("=" * 50)
